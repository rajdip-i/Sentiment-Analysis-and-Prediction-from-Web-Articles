{
 "cells": [
  {
   "cell_type": "raw",
   "id": "026eef2a-3fdf-4778-b83e-ea52facd7910",
   "metadata": {},
   "source": [
    "Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19af036c-456e-4109-b1da-af0503f17119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rajdipingale/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/rajdipingale/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "nltk.download('punkt')\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cd0822-baaa-4c25-aa05-34c4065dc7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b5452a-174b-4958-aa20-ffe7dbd8ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbee7d4b-3223-4cab-bf11-d97b747b6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Assuming the article title is within the <title> tag\n",
    "    title = soup.title.string if soup.title else 'No Title'\n",
    "\n",
    "    # Extract the article text\n",
    "    # Here we assume that the main article content is within <article> tag\n",
    "    # This might need to be adjusted depending on the website's structure\n",
    "    article_text = ''\n",
    "    article = soup.find('article')\n",
    "    if article:\n",
    "        paragraphs = article.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            article_text += paragraph.get_text() + '\\n'\n",
    "    else:\n",
    "        # Fallback: Extract all text from <p> tags\n",
    "        paragraphs = soup.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            article_text += paragraph.get_text() + '\\n'\n",
    "    \n",
    "    return title, article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa000c3b-895d-43a9-9e0f-28366296acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel('/Users/rajdipingale/Desktop/Projects/Sentiment Analysis and Prediction from Web Articles/Input.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35364be1-42b2-4293-b9d6-c03412eabc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted and saved article bctech2011\n",
      "Successfully extracted and saved article bctech2012\n",
      "Successfully extracted and saved article bctech2013\n",
      "Successfully extracted and saved article bctech2014\n",
      "Successfully extracted and saved article bctech2015\n",
      "Successfully extracted and saved article bctech2016\n",
      "Successfully extracted and saved article bctech2017\n",
      "Successfully extracted and saved article bctech2018\n",
      "Successfully extracted and saved article bctech2019\n",
      "Successfully extracted and saved article bctech2020\n",
      "Successfully extracted and saved article bctech2021\n",
      "Successfully extracted and saved article bctech2022\n",
      "Successfully extracted and saved article bctech2023\n",
      "Successfully extracted and saved article bctech2024\n",
      "Successfully extracted and saved article bctech2025\n",
      "Successfully extracted and saved article bctech2026\n",
      "Successfully extracted and saved article bctech2027\n",
      "Successfully extracted and saved article bctech2028\n",
      "Successfully extracted and saved article bctech2029\n",
      "Successfully extracted and saved article bctech2030\n",
      "Successfully extracted and saved article bctech2031\n",
      "Successfully extracted and saved article bctech2032\n",
      "Successfully extracted and saved article bctech2033\n",
      "Successfully extracted and saved article bctech2034\n",
      "Successfully extracted and saved article bctech2035\n",
      "Successfully extracted and saved article bctech2036\n",
      "Successfully extracted and saved article bctech2037\n",
      "Successfully extracted and saved article bctech2038\n",
      "Successfully extracted and saved article bctech2039\n",
      "Successfully extracted and saved article bctech2040\n",
      "Successfully extracted and saved article bctech2041\n",
      "Successfully extracted and saved article bctech2042\n",
      "Successfully extracted and saved article bctech2043\n",
      "Successfully extracted and saved article bctech2044\n",
      "Successfully extracted and saved article bctech2045\n",
      "Successfully extracted and saved article bctech2046\n",
      "Successfully extracted and saved article bctech2047\n",
      "Successfully extracted and saved article bctech2048\n",
      "Successfully extracted and saved article bctech2049\n",
      "Successfully extracted and saved article bctech2050\n",
      "Successfully extracted and saved article bctech2051\n",
      "Successfully extracted and saved article bctech2052\n",
      "Successfully extracted and saved article bctech2053\n",
      "Successfully extracted and saved article bctech2054\n",
      "Successfully extracted and saved article bctech2055\n",
      "Successfully extracted and saved article bctech2056\n",
      "Successfully extracted and saved article bctech2057\n",
      "Successfully extracted and saved article bctech2058\n",
      "Successfully extracted and saved article bctech2059\n",
      "Successfully extracted and saved article bctech2060\n",
      "Successfully extracted and saved article bctech2061\n",
      "Successfully extracted and saved article bctech2062\n",
      "Successfully extracted and saved article bctech2063\n",
      "Successfully extracted and saved article bctech2064\n",
      "Successfully extracted and saved article bctech2065\n",
      "Successfully extracted and saved article bctech2066\n",
      "Successfully extracted and saved article bctech2067\n",
      "Successfully extracted and saved article bctech2068\n",
      "Successfully extracted and saved article bctech2069\n",
      "Successfully extracted and saved article bctech2070\n",
      "Successfully extracted and saved article bctech2071\n",
      "Successfully extracted and saved article bctech2072\n",
      "Successfully extracted and saved article bctech2073\n",
      "Successfully extracted and saved article bctech2074\n",
      "Successfully extracted and saved article bctech2075\n",
      "Successfully extracted and saved article bctech2076\n",
      "Successfully extracted and saved article bctech2077\n",
      "Successfully extracted and saved article bctech2078\n",
      "Successfully extracted and saved article bctech2079\n",
      "Successfully extracted and saved article bctech2080\n",
      "Successfully extracted and saved article bctech2081\n",
      "Successfully extracted and saved article bctech2082\n",
      "Successfully extracted and saved article bctech2083\n",
      "Successfully extracted and saved article bctech2084\n",
      "Successfully extracted and saved article bctech2085\n",
      "Successfully extracted and saved article bctech2086\n",
      "Successfully extracted and saved article bctech2087\n",
      "Successfully extracted and saved article bctech2088\n",
      "Successfully extracted and saved article bctech2089\n",
      "Successfully extracted and saved article bctech2090\n",
      "Successfully extracted and saved article bctech2091\n",
      "Successfully extracted and saved article bctech2092\n",
      "Successfully extracted and saved article bctech2093\n",
      "Successfully extracted and saved article bctech2094\n",
      "Successfully extracted and saved article bctech2095\n",
      "Successfully extracted and saved article bctech2096\n",
      "Successfully extracted and saved article bctech2097\n",
      "Successfully extracted and saved article bctech2098\n",
      "Successfully extracted and saved article bctech2099\n",
      "Successfully extracted and saved article bctech2100\n",
      "Successfully extracted and saved article bctech2101\n",
      "Successfully extracted and saved article bctech2102\n",
      "Successfully extracted and saved article bctech2103\n",
      "Successfully extracted and saved article bctech2104\n",
      "Successfully extracted and saved article bctech2105\n",
      "Successfully extracted and saved article bctech2106\n",
      "Successfully extracted and saved article bctech2107\n",
      "Successfully extracted and saved article bctech2108\n",
      "Successfully extracted and saved article bctech2109\n",
      "Successfully extracted and saved article bctech2110\n",
      "Successfully extracted and saved article bctech2111\n",
      "Successfully extracted and saved article bctech2112\n",
      "Successfully extracted and saved article bctech2113\n",
      "Successfully extracted and saved article bctech2114\n",
      "Successfully extracted and saved article bctech2115\n",
      "Successfully extracted and saved article bctech2116\n",
      "Successfully extracted and saved article bctech2117\n",
      "Successfully extracted and saved article bctech2118\n",
      "Successfully extracted and saved article bctech2119\n",
      "Successfully extracted and saved article bctech2120\n",
      "Successfully extracted and saved article bctech2121\n",
      "Successfully extracted and saved article bctech2122\n",
      "Successfully extracted and saved article bctech2123\n",
      "Successfully extracted and saved article bctech2124\n",
      "Successfully extracted and saved article bctech2125\n",
      "Successfully extracted and saved article bctech2126\n",
      "Successfully extracted and saved article bctech2127\n",
      "Successfully extracted and saved article bctech2128\n",
      "Successfully extracted and saved article bctech2129\n",
      "Successfully extracted and saved article bctech2130\n",
      "Successfully extracted and saved article bctech2131\n",
      "Successfully extracted and saved article bctech2132\n",
      "Successfully extracted and saved article bctech2133\n",
      "Successfully extracted and saved article bctech2134\n",
      "Successfully extracted and saved article bctech2135\n",
      "Successfully extracted and saved article bctech2136\n",
      "Successfully extracted and saved article bctech2137\n",
      "Successfully extracted and saved article bctech2138\n",
      "Successfully extracted and saved article bctech2139\n",
      "Successfully extracted and saved article bctech2140\n",
      "Successfully extracted and saved article bctech2141\n",
      "Successfully extracted and saved article bctech2142\n",
      "Successfully extracted and saved article bctech2143\n",
      "Successfully extracted and saved article bctech2144\n",
      "Successfully extracted and saved article bctech2145\n",
      "Successfully extracted and saved article bctech2146\n",
      "Successfully extracted and saved article bctech2147\n",
      "Successfully extracted and saved article bctech2148\n",
      "Successfully extracted and saved article bctech2149\n",
      "Successfully extracted and saved article bctech2150\n",
      "Successfully extracted and saved article bctech2151\n",
      "Successfully extracted and saved article bctech2152\n",
      "Successfully extracted and saved article bctech2153\n",
      "Successfully extracted and saved article bctech2154\n",
      "Successfully extracted and saved article bctech2155\n",
      "Successfully extracted and saved article bctech2156\n",
      "Successfully extracted and saved article bctech2157\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "df['Extracted_Article'] = None  # Initialize the column with None or empty strings\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    try:\n",
    "        # Extract the title and article text from the URL\n",
    "        title, article_text = extract_article(url)\n",
    "        \n",
    "        # Combine title and article text\n",
    "        full_article = title + '\\n\\n' + article_text\n",
    "        \n",
    "        # Save the combined text in the new DataFrame column\n",
    "        df.at[index, 'Extracted_Article'] = full_article\n",
    "        \n",
    "        print(f'Successfully extracted and saved article {url_id}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to extract article {url_id} from {url}: {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69472c75-ff6a-4bb1-ba61-63abd9de1c15",
   "metadata": {},
   "source": [
    "Sentiment Analysisa. Remove stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e34f3f2-de0b-4166-90dd-3c6bbe9567fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load stopwords from text files\n",
    "def load_stopwords(stopwords_dir, encoding='utf-8'):\n",
    "    stopwords = set()\n",
    "    for filename in os.listdir(stopwords_dir):\n",
    "        file_path = os.path.join(stopwords_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
    "                for line in file:\n",
    "                    stopwords.add(line.strip().lower())\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1318b2-3c30-4463-bf3a-72c7a57112a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from text\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = text.split()\n",
    "    cleaned_text = ' '.join([word for word in words if word.lower() not in stopwords])\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077c75c1-f5bc-44bf-b578-64097766909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the stopword text files\n",
    "stopwords_dir = '/Users/rajdipingale/Desktop/Projects/Sentiment Analysis and Prediction from Web Articles/StopWords'\n",
    "\n",
    "# Load the stopwords\n",
    "stopwords = load_stopwords(stopwords_dir, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e47e89-c91c-4d71-97cf-8426276219d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store the cleaned article text\n",
    "df['Cleaned_Article'] = None\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Extracted_Article']\n",
    "    \n",
    "    # Remove stopwords from the text\n",
    "    cleaned_text = remove_stopwords(text, stopwords)\n",
    "    \n",
    "    # Save the cleaned text back into the DataFrame\n",
    "    df.at[index, 'Cleaned_Article'] = cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88610aea-9358-4f39-b23f-13d34be9e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_words(master_dict_file, stopwords, encoding='utf-8'):\n",
    "    words = set()\n",
    "    with open(master_dict_file, 'r', encoding=encoding, errors='ignore') as file:\n",
    "        for line in file:\n",
    "            word = line.strip().lower()\n",
    "            if word and word not in stopwords:\n",
    "                words.add(word)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22d4524-f1a5-4e48-bf56-5487a0aebd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_file = '/Users/rajdipingale/Desktop/Projects/Sentiment Analysis and Prediction from Web Articles/MasterDictionary/positive-words.txt'\n",
    "negative_words_file = '/Users/rajdipingale/Desktop/Projects/Sentiment Analysis and Prediction from Web Articles/MasterDictionary/negative-words.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2821cea-6a60-4f9e-9616-96d5ffd584ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter positive and negative words\n",
    "positive_words = list(load_and_filter_words(positive_words_file, stopwords, encoding='utf-8'))\n",
    "negative_words = list(load_and_filter_words(negative_words_file, stopwords, encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742448c6-6309-495a-b5aa-4fa10660ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positive Words:\", positive_words)\n",
    "print(\"Negative Words:\", negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d5934b6-4718-4d81-bcca-725a1324a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate the scores\n",
    "def calculate_scores(text, positive_words, negative_words):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    positive_score = sum(1 for word in tokens if word in positive_words)\n",
    "    negative_score = sum(1 for word in tokens if word in negative_words)\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return polarity_score*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82d0e738-ef1e-419d-bcf4-377465306385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the polarity scores and add them to the DataFrame\n",
    "df['Polarity Score'] = df['Cleaned_Article'].apply(lambda x: calculate_scores(x, positive_words, negative_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a688fe0-61fe-47dc-b5e8-bfcecfbba84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Extracted_Article</th>\n",
       "      <th>Cleaned_Article</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2011</td>\n",
       "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
       "      <td>ML and AI-based insurance premium model to pre...</td>\n",
       "      <td>ML AI-based insurance premium model predict pr...</td>\n",
       "      <td>6.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2012</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
       "      <td>Streamlined Integration: Interactive Brokers A...</td>\n",
       "      <td>Streamlined Integration: Interactive Brokers A...</td>\n",
       "      <td>9.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2013</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
       "      <td>Efficient Data Integration and User-Friendly I...</td>\n",
       "      <td>Efficient Data Integration User-Friendly Inter...</td>\n",
       "      <td>9.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2014</td>\n",
       "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
       "      <td>Effective Management of Social Media Data Extr...</td>\n",
       "      <td>Effective Management Social Media Data Extract...</td>\n",
       "      <td>9.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2015</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
       "      <td>Streamlined Trading Operations Interface for M...</td>\n",
       "      <td>Streamlined Trading Operations Interface MetaT...</td>\n",
       "      <td>9.999997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       URL_ID                                                URL  \\\n",
       "0  bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...   \n",
       "1  bctech2012  https://insights.blackcoffer.com/streamlined-i...   \n",
       "2  bctech2013  https://insights.blackcoffer.com/efficient-dat...   \n",
       "3  bctech2014  https://insights.blackcoffer.com/effective-man...   \n",
       "4  bctech2015  https://insights.blackcoffer.com/streamlined-t...   \n",
       "\n",
       "                                   Extracted_Article  \\\n",
       "0  ML and AI-based insurance premium model to pre...   \n",
       "1  Streamlined Integration: Interactive Brokers A...   \n",
       "2  Efficient Data Integration and User-Friendly I...   \n",
       "3  Effective Management of Social Media Data Extr...   \n",
       "4  Streamlined Trading Operations Interface for M...   \n",
       "\n",
       "                                     Cleaned_Article  Polarity Score  \n",
       "0  ML AI-based insurance premium model predict pr...        6.190476  \n",
       "1  Streamlined Integration: Interactive Brokers A...        9.999995  \n",
       "2  Efficient Data Integration User-Friendly Inter...        9.999997  \n",
       "3  Effective Management Social Media Data Extract...        9.999995  \n",
       "4  Streamlined Trading Operations Interface MetaT...        9.999997  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a886d4c-f8fe-4cda-9afa-88ae1c45060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471ceb0-9881-48c1-b88a-82cfcd6403f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d078de57-357c-483d-b49c-4ddc53547a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = []\n",
    "for doc in df['Cleaned_Article']:\n",
    "    raw_sent = sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e21259d0-5b95-4940-912f-2cef85ab5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "076aaaa4-d6ee-48a6-b7b5-813c2cf89f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34a67c3d-4bf9-429b-baec-5dca143c413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97970, 121965)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6585c736-eec1-4483-9228-f173ba46959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2220"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "148635fe-7550-4446-90d0-7c8f5e410f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45e75860-0a6d-460a-a906-59e836ed0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20684879,  0.2020967 , -0.00178433,  0.10398842,  0.01382534,\n",
       "       -0.48018152,  0.11183865,  0.48722053, -0.18665679, -0.14025079,\n",
       "       -0.1152152 , -0.35958412, -0.17670296,  0.1642435 ,  0.12704533,\n",
       "       -0.16552097,  0.03457852, -0.28552842,  0.03209473, -0.4690563 ,\n",
       "        0.16545556,  0.04257831,  0.18595906, -0.15180638, -0.10106605,\n",
       "        0.11936492, -0.18276818, -0.14157732, -0.23707482,  0.05992527,\n",
       "        0.26392105, -0.06218736,  0.08610237, -0.16368271, -0.04899084,\n",
       "        0.1104377 ,  0.00115286, -0.18862389, -0.03566688, -0.44787744,\n",
       "        0.08343272, -0.22661938, -0.22572745, -0.03399974,  0.10953996,\n",
       "       -0.15054241, -0.08578535, -0.11812308,  0.05748444,  0.1799875 ,\n",
       "        0.04710894, -0.39491308, -0.03773792, -0.04355729, -0.06985509,\n",
       "        0.17842574,  0.12845874,  0.05221111, -0.37001482,  0.15313001,\n",
       "        0.06398661, -0.01896054,  0.01136607, -0.02682653, -0.1910794 ,\n",
       "        0.20587204,  0.09074128,  0.23620519, -0.2801882 ,  0.49188173,\n",
       "       -0.06512186,  0.08618809,  0.31077796, -0.15472245,  0.21794967,\n",
       "        0.0667996 ,  0.12989967, -0.01451829, -0.28166658,  0.03389933,\n",
       "       -0.21033725, -0.10004193, -0.19424984,  0.2947046 , -0.15285903,\n",
       "       -0.09556127,  0.06073749,  0.28960738,  0.07331448,  0.05367778,\n",
       "        0.3205766 ,  0.09758461, -0.05771759,  0.09078313,  0.38234854,\n",
       "        0.16532494,  0.0824968 , -0.13515396, -0.05646375, -0.04404787],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df['Cleaned_Article'].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf8cfaba-9e84-4ab4-9fa1-94759b1881ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(49262) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|████████████████████████████████████████| 147/147 [00:00<00:00, 460.46it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for doc in tqdm(df['Cleaned_Article'].values):\n",
    "    X.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ed8cf1a-7b00-410a-9218-464e8104b87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20684879,  0.2020967 , -0.00178433,  0.10398842,  0.01382534,\n",
       "       -0.48018152,  0.11183865,  0.48722053, -0.18665679, -0.14025079,\n",
       "       -0.1152152 , -0.35958412, -0.17670296,  0.1642435 ,  0.12704533,\n",
       "       -0.16552097,  0.03457852, -0.28552842,  0.03209473, -0.4690563 ,\n",
       "        0.16545556,  0.04257831,  0.18595906, -0.15180638, -0.10106605,\n",
       "        0.11936492, -0.18276818, -0.14157732, -0.23707482,  0.05992527,\n",
       "        0.26392105, -0.06218736,  0.08610237, -0.16368271, -0.04899084,\n",
       "        0.1104377 ,  0.00115286, -0.18862389, -0.03566688, -0.44787744,\n",
       "        0.08343272, -0.22661938, -0.22572745, -0.03399974,  0.10953996,\n",
       "       -0.15054241, -0.08578535, -0.11812308,  0.05748444,  0.1799875 ,\n",
       "        0.04710894, -0.39491308, -0.03773792, -0.04355729, -0.06985509,\n",
       "        0.17842574,  0.12845874,  0.05221111, -0.37001482,  0.15313001,\n",
       "        0.06398661, -0.01896054,  0.01136607, -0.02682653, -0.1910794 ,\n",
       "        0.20587204,  0.09074128,  0.23620519, -0.2801882 ,  0.49188173,\n",
       "       -0.06512186,  0.08618809,  0.31077796, -0.15472245,  0.21794967,\n",
       "        0.0667996 ,  0.12989967, -0.01451829, -0.28166658,  0.03389933,\n",
       "       -0.21033725, -0.10004193, -0.19424984,  0.2947046 , -0.15285903,\n",
       "       -0.09556127,  0.06073749,  0.28960738,  0.07331448,  0.05367778,\n",
       "        0.3205766 ,  0.09758461, -0.05771759,  0.09078313,  0.38234854,\n",
       "        0.16532494,  0.0824968 , -0.13515396, -0.05646375, -0.04404787],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b661169b-f580-47f6-aefe-bc2eccb5b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Polarity Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8eed2-a329-4127-8189-e19ae045125c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "546aa9f0-7a91-4efa-8713-6f417500d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e52cf05-f1d6-48f5-9359-706bedcc5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(actual, pred):\n",
    "    MAE = mean_absolute_error(actual, pred)\n",
    "    MSE = mean_squared_error(actual, pred)\n",
    "    RMSE = np.sqrt(mean_squared_error(actual, pred))\n",
    "    SCORE = r2_score(actual, pred)\n",
    "    return print(f\"R2 Score: {SCORE:.4f} \\nMean Absolute Error:{MAE:.4f},\\nMean Squared Error:{MSE:.4f} \\nRoot Mean Squared Error:{RMSE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08113ece-ddd2-4a5d-aae5-997a8a976ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "854933ad-fee6-4980-96e0-57f0c4ecee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -6.4537 \n",
      "Mean Absolute Error:8.7386,\n",
      "Mean Squared Error:118.5955 \n",
      "Root Mean Squared Error:10.8902\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "prediction_lr = model_lr.fit(X_train, y_train).predict(X_test)\n",
    "evaluation_metrics(y_test, prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59f499ed-a15a-46cb-92c7-29f3b57830c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.0137 \n",
      "Mean Absolute Error:3.1913,\n",
      "Mean Squared Error:15.6929 \n",
      "Root Mean Squared Error:3.9614\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor()\n",
    "prediction_rf = model_rf.fit(X_train, y_train).predict(X_test)\n",
    "evaluation_metrics(y_test, prediction_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e195dd8b-3ed1-421b-a4e1-dcbccd5e6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.0621 \n",
      "Mean Absolute Error:3.0251,\n",
      "Mean Squared Error:14.9227 \n",
      "Root Mean Squared Error:3.8630\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVR()\n",
    "prediction_svm = model_svm.fit(X_train, y_train).predict(X_test)\n",
    "evaluation_metrics(y_test, prediction_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab5b2f9a-2383-41a9-8a71-f745b17c52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.2987 \n",
      "Mean Absolute Error:3.4592,\n",
      "Mean Squared Error:20.6633 \n",
      "Root Mean Squared Error:4.5457\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBRegressor()\n",
    "prediction_xgb = model_xgb.fit(X_train, y_train).predict(X_test)\n",
    "evaluation_metrics(y_test, prediction_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d7022e6-2190-4654-9e58-ff05787b85b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>14.922659</td>\n",
       "      <td>3.862986</td>\n",
       "      <td>3.025068</td>\n",
       "      <td>0.062113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>15.692880</td>\n",
       "      <td>3.961424</td>\n",
       "      <td>3.191322</td>\n",
       "      <td>0.013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>20.663349</td>\n",
       "      <td>4.545696</td>\n",
       "      <td>3.459182</td>\n",
       "      <td>-0.298689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>118.595517</td>\n",
       "      <td>10.890157</td>\n",
       "      <td>8.738648</td>\n",
       "      <td>-6.453712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model         MSE       RMSE       MAE  R2_SCORE\n",
       "0  Support Vector Machines   14.922659   3.862986  3.025068  0.062113\n",
       "1            Random Forest   15.692880   3.961424  3.191322  0.013705\n",
       "2                  XGBoost   20.663349   4.545696  3.459182 -0.298689\n",
       "3        Linear Regression  118.595517  10.890157  8.738648 -6.453712"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    'Model': ['  Linear Regression', 'Random Forest', 'Support Vector Machines', ' XGBoost'],\n",
    "    'MSE': [],\n",
    "    'RMSE': [],\n",
    "    'MAE': [],\n",
    "    'R2_SCORE': []\n",
    "}\n",
    "\n",
    "for model_name, pred in zip(results['Model'], [prediction_lr, prediction_rf, prediction_svm, prediction_xgb]):\n",
    "    results['MSE'].append(mean_squared_error(y_test, pred))\n",
    "    results['RMSE'].append(np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    results['MAE'].append(mean_absolute_error(y_test, pred))\n",
    "    results['R2_SCORE'].append(r2_score(y_test, pred))\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results.sort_values(by=\"MSE\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6cb610-82b0-4158-bb8c-0c9027369ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
